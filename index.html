<!DOCTYPE HTML>
<html>
	<head>
		<title>Impaired Driver Detection</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

			<section id="header" class="dark">
				<header>
					<h1>Impaired Driver Detection</h1>
					<p>Sudheesh, Aarav, Ainesh</p>
				</header>
			</section>

			<section id="first" class="main">
				<header>
					<div class="container">
						<h2>Motivation</h2>
						<p>Impaired drivers (inattentive, drowsy, under the influence) contribute to around 50% of accidents on the road in the U.S. 
							These accidents contribute to around 15,000 deaths per year in the US (275,000 worldwide), making this an important issue that we hope to address. 
							Thus for our project, we want to detect such drivers using computer vision via dashcam in the car, 
							and issue a warning to the driver, or even lock the vehicle, to prevent these accidents before they happen.</p>
					</div>
				</header>
				<div class="content dark style1 featured">
					<div class="container">
							<section>
							<header>
								<h3>State of the Art</h3>
								<p>Drowsy Driver</p>
							</header>
							<p>There is currently no all encompasing ready to use in any vehicle solution for detecting impaired drivers.
								One solution is <a href="https://www.tesla.com/ownersmanual/model3/en_us/GUID-EDAD116F-3C73-40FA-A861-68112FF7961F.html">Tesla's interior camera</a> for monitoring the driver when FSD is turned on. However, from what Tesla has released, this only attempts to detect that the driver is looking towards the road, and does not attempt to detect other types of impairement like drowsiness. Additionally, this is only available in Teslas.
								<a href="https://www.samsara.com/blog/drowsiness-detection-samsara-sets-standard">Samsara</a> released a comprehensive approach for detecting drowsy drivers in 2024, targeted towards truck drivers. However, their solution only detects drowsy drivers by looking for queues like yawns and head nods, but does try to detect other types of impairement. Thus, this solution is limited and less applicable for everyday use.
								Another approach is to monitor steering, however detecting poor steering might not happen quick enough to prevent an accident, and poor steering is not representative of impairment as a driver may have bad reaction time (due to impairment) but maintain acceptable steering patterns. 
							</p>
							</section>
						</div>
					</div>
			</section>

			<section id="second" class="main">
				<header>
					<div class="container">
						<h2>Approach and Implementation</h2>
						<p>Impaired Driver</p>
						<p>To accomplish our goal, we implemented a pipeline consisting of two Convolutional Neural Networks (CNN) that we developed the architecture for and trained with data we found (linked at the bottom) using keras with TensorFlow in python, followed by a post classifier. 
							Our first CNN is a regression model that detects the driver in the image. Our second CNN is a binary classification model that uses the detected driver as input, and determines if the driver is attentive to the road or not (head is facing forward means attentive).
							 If this model determines the driver to be attentive, the cropped image of the driver is sent through the post classifier. This determines if the driver is drowsy or under the influence by looking for yawns, closed eyes, or head nodding by counting pixels in expected locations of the mouth and eyes.
							  The reason we split this into two models and a post classifier was we struggled to find datasets; most datasets for classifying the state of a face were focused on the face,
							   meaning our model would struggle when given an image from a dashcam. We also attempted to join multiple smaller datasets of images from a dashcam focused on inattentive drivers or drowsy drives together.
							    However, this resulted in heavy class imbalance and inconsistency in the location from which the image of the driver was taken. 
								Thus, we decided to split the bigger problem into smaller ones and solve those with the respective smaller datasets that we found.
						</p>
						<p>
							This is a diagram of what our pipeline looks like:
						</p>
						<span class="image featured"><img src="images/pipeline.png" alt="" /></span>
						<p>
							This is sample flow of images:
						</p>
						<span class="image featured"><img src="images/pipelineRealImages.png" alt="" /></span>
					</div>
				</header>
				<div class="content style1 dark">
					<div class="container">
								<section>
									<h3>Issues we faced along the way</h3>
									<h5>Until the midterm report</h5>
									<p>Our initial plan was to rely on OpenCV’s HAAR cascade classifier for face detection to find the driver and then develop + train our own model for classifying state of the driver, HAAR cascade proved unreliable for images captured from a dashboard perspective. 
									Although effective with standard, front-facing portraits, the classifier struggled with varied angles, lighting, and partial occlusions typical of in-car dashcam footage. 
									To address this limitation, we pivoted to training our custom TensorFlow keras CNN for driver localization using a small labeled Roboflow dataset.
									This pivot introduced new challenges of model complexity and computational limits. As mentioned in the section above, due to dataset limitations, we decided here to make two models, one for driver detection and one for classifying state of the driver. 
									</p>
									<h4>Until Final Presentation</h4>
									<p>Our initial plan for our driver state classification model was to classify if the driver was attentive, inattentive, drowsy, or under the influence in one model.
										 However, we ran into issues with developing and training a model with more than two classes largely due to the dataset limitations and imbalance when combining multiple datasets. 
										Also, increasing model complexity for improved accuracy was not viable due to compute power limitations, as we trained everything on our personal machines.
										 So we decided here to pivot towards training a model to classify the driver as attentive and facing the road, or inattentive, and develop a post classifier for determining if the driver was drowsy or under the influence.
									</p>
								</section>
							</div>
						</div>
					</div>
				</div>
			</section>

			<section id="third" class="main">
				<header>
					<div class="container">
						<h2>Results</h2>
						<p>In this image the driver is facing forward but eyes are closed, so we expect post classification to catch impaired, and it does:</p>
						<span class="image featured"><img src="images/EyesClosedResult.png" alt="" /></span>
						<p>In this image the driver is turned to the left, so we expect our attention classification model to detect inattentive, and it does:</p>
						<span class="image featured"><img src="images/InattentiveResult.png" alt="" /></span>
						<p>In this image the driver is attentive, so we expect the driver to be marked as attentive and not impaired, and they are:</p>
						<span class="image featured"><img src="images/AttentiveResult.png" alt="" /></span>
						<p>In this image the driver is inattentive looking at something on the left, so we again expect our attention classification model to detect inattentive, and it does:</p>
						<span class="image featured"><img src="images/InattentiveDiffDriverResult.png" alt="" /></span>
					</div>
				</header>
			</section>
		<section id="fourth" class="main">
			<div class="content style1 dark">
					<div class="container">
						<section>
							<header>
								<h3>Further ideas</h3>
							</header>
							<p>If we had additional time to extend our completed system, we would gather better data and broaden our classifier from binary classification into a multi classification model capable of distinguishing not only attentiveness but also drowsiness and other types of impairement, so that we would only need one model end to end. 
								</p><p>If this is not possible, and we were to keep our pipeline, we definitely would improve our post classifier to look for Eye Aspect Ratio (EAR) and Mouth Aspect Ratio (MAR) for detecting drowsiness and being under the influence for more accuracy.
								</p><p>We also see opportunity to evolve our existing inference pipeline into a fully real-time application by running inference on live webcam footage. Further polish could include a more sophisticated visualization interface, featuring color-coded state predictions, supplemental cues like EAR and MAR charts if we switch to using those, and exportable video clips for crash proof. 
								These enhancements would make our system more practical, interpretable, and deployable in real driving environments.</p>
						</section>
		</div>
		</div>
		</section>
		
			<section id="fourth" class="main">
				<div class="content style1 dark">
					<div class="container">
						<header>
								<h3>Sources and Data Links</h3>
							</header>
							<ul class="default">
								<h2>Sources</h2>
								<li>Hou, Junjian. “A Systematic Review for the Fatigue Driving Behavior Recognition Method - Junjian Hou, Yaxiong Xu, Wenbin He, Yudong Zhong, Dengfeng Zhao, Fang Zhou, Mingyuan Zhao, Shesen Dong, 2024.” 
									Journal of Intelligent & Fuzzy Systems: Applications in Engineering and Technology, Journal of Intelligent & Fuzzy Systems: Applications in Engineering and Technology, 18 Nov. 2023.  <a href="journals.sagepub.com/doi/full/10.3233/JIFS-235075">Link to report</a>
								</li>
								<li>Liu, Fan, et al. “A Review of Driver Fatigue Detection and Its Advances on The ...” A Review of Driver Fatigue Detection and Its Advances on the Use of RGB-D Camera and Deep Learning, Key Laboratory of Water Big Data Technology of Ministry of Water Resources, Hohai University, Nanjing, China, Nov. 2022. <a href="multimodality.group/publication/eaai2022review/A%20review%20of%20driver%20fatigue%20detection%20and%20its%20advances%20on%20the%20use%20of%20RGB-D.pdf">Link to report</a> 
								</li>
								<li>Soultana, Abdelfettah, et al. “A Systematic Literature Review of Driver Inattention Monitoring Systems for Smart Car.” International Journal of Interactive Mobile Technologies (iJIM), Laboratory of Modeling and Information Technology Faculty of Sciences Ben M’SIK University Hassan II, 31 Aug. 2022. <a href="online-journals.org/index.php/i-jim/article/view/33075">Link to report</a> 
								</li>
								<h2>Data</h2>
								<li>Data for face detection - <a href="https://universe.roboflow.com/computer-vision-project-ehipo/driver-face-detection-dzicg">Link</a>
								</li>
								<li>Dataset for classification - <a href="https://universe.roboflow.com/si-bridges/distracted-driving-wuu1n">Link</a>
								<br>
								<h2>Reports</h2>
								<li>Project Proposal - <a href="https://docs.google.com/document/d/1Xvg1fYXNDsIdT9YKROK0_mmb4pUJMxz5IQQYLmTTHUE/edit?usp=sharing">Link</a>
								</li>
								<li>Midterm Report - <a href="https://docs.google.com/document/d/1IbhU7jkqAB2i8MAc_e2UsXxVjukievzIBwDKjNNcbdU/edit?usp=sharing">Link</a>
								</li>
							</ul>
					</div>
				</div>
			</section>

			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>